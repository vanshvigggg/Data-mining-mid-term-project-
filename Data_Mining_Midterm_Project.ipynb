{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Mining Midterm Project - Vansh Vig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from itertools import combinations\n",
    "from collections import defaultdict\n",
    "from mlxtend.frequent_patterns import apriori, association_rules, fpgrowth\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Select the dataset: \n",
      "     (1) Amazon books dataset \n",
      "     (2) BestBuy dataset \n",
      "     (3) Generic dataset \n",
      "     (4) Grocery Store dataset \n",
      "     (5) K-mart dataset \n",
      "     (6) Nike datatset \n",
      "     Please enter your choice (1 to 6) :  4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Grocery Store dataset\n"
     ]
    }
   ],
   "source": [
    "def read_dataset(choice):\n",
    "    if choice == 1:\n",
    "        print(\"Reading Amazon books dataset\")\n",
    "        df = pd.read_csv('AmazonBooks.csv')\n",
    "    elif choice == 2:\n",
    "        print(\"Reading BestBuy dataset\")\n",
    "        df = pd.read_csv('BestBuy.csv')\n",
    "    elif choice == 3:\n",
    "        print(\"Reading Generic dataset\")\n",
    "        df = pd.read_csv('Generic.csv')\n",
    "    elif choice == 4:\n",
    "        print(\"Reading Grocery Store dataset\")\n",
    "        df = pd.read_csv('Grocery Store.csv')\n",
    "    elif choice == 5:\n",
    "        print(\"Reading K-mart dataset\")\n",
    "        df = pd.read_csv('K-Mart.csv')\n",
    "    elif choice == 6:\n",
    "        print(\"Reading Nike dataset\")\n",
    "        df = pd.read_csv('Nike.csv')\n",
    "    else:\n",
    "        print(\"not a valid input, please select between 1 to 6\")\n",
    "        return None\n",
    "    return df\n",
    "\n",
    "# Get user input\n",
    "choice = int(input(\"Select the dataset: \\n \\\n",
    "    (1) Amazon books dataset \\n \\\n",
    "    (2) BestBuy dataset \\n \\\n",
    "    (3) Generic dataset \\n \\\n",
    "    (4) Grocery Store dataset \\n \\\n",
    "    (5) K-mart dataset \\n \\\n",
    "    (6) Nike datatset \\n \\\n",
    "    Please enter your choice (1 to 6) : \"))\n",
    "\n",
    "# Read the dataset based on the user input\n",
    "df = read_dataset(choice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  milk bread biscuit cornflakes bournvita  jam maggi  tea coffee cock sugar\n",
      "0    t     t       t        NaN       NaN  NaN   NaN  NaN    NaN  NaN   NaN\n",
      "1    t     t       t          t       NaN  NaN   NaN  NaN    NaN  NaN   NaN\n",
      "2  NaN     t     NaN        NaN         t  NaN   NaN    t    NaN  NaN   NaN\n",
      "3    t     t     NaN        NaN       NaN    t     t  NaN    NaN  NaN   NaN\n",
      "4  NaN   NaN       t        NaN       NaN  NaN     t    t    NaN  NaN   NaN\n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the Minimum Support and Minimum Confidence Values from the user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the Minimum Support (eg. 30):  30\n"
     ]
    }
   ],
   "source": [
    "min_support_value = int(input(\"Enter the Minimum Support (eg. 30): \"))\n",
    "min_support = (min_support_value)/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the Minimun Confidence eg. (20) :  20\n"
     ]
    }
   ],
   "source": [
    "confidence = int(input(\"Enter the Minimun Confidence eg. (20) : \"))\n",
    "min_confidence = (confidence)/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum Support Value :  0.3\n",
      "Minimum Confidence Value :  0.2\n"
     ]
    }
   ],
   "source": [
    "print(\"Minimum Support Value : \",min_support)\n",
    "print(\"Minimum Confidence Value : \", min_confidence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the Brute Force code from the Brute_Force_Code.py file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "level : 1 2 3 \n",
      "\n",
      "Number of rules:  0 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from Brute_Force_Code import BruteForceAssociation\n",
    "\n",
    "start_bruteforce = time.time()\n",
    "associations = BruteForceAssociation(df, min_support, min_confidence)\n",
    "\n",
    "# Print the association rules\n",
    "print(\"Number of rules: \", len(associations), \"\\n\\n\")\n",
    "for rule in associations:\n",
    "    print(f\"{set(rule[0])} -> {set(rule[1])} <confidence: {rule[2]}>\")\n",
    "\n",
    "end_bruteforce = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time taken for brute force code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 1.9979476928710938 ms\n"
     ]
    }
   ],
   "source": [
    "time_taken = (end_bruteforce - start_bruteforce)*1000\n",
    "print(\"Time taken:\", time_taken, \"ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing the dataset to fit in the python library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tf/kbd3k_cx24g7h3zmjh0vyk3c0000gp/T/ipykernel_40549/1390967614.py:2: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  data = data.fillna(False)\n"
     ]
    }
   ],
   "source": [
    "data = df.replace('t', True)\n",
    "data = data.fillna(False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the apriori and association_rules function from the mlxtend library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of rules : 0\n"
     ]
    }
   ],
   "source": [
    "start_apriori = time.time()\n",
    "# Generate frequent itemsets\n",
    "frequent_itemsets = apriori(data, min_support=min_support, use_colnames=True)  # Use column names if applicable\n",
    "\n",
    "# Generate association rules\n",
    "rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=min_confidence)\n",
    "print(\"No. of rules :\" , len(rules))\n",
    "\n",
    "end_apriori = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time taken for Apriori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for Apriori Algorithm: 3.1821727752685547 ms\n"
     ]
    }
   ],
   "source": [
    "time_taken = (end_apriori - start_apriori)*1000\n",
    "print(\"Time taken for Apriori Algorithm:\", time_taken, \"ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results of apriori algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequent itemsets:\n",
      "   support      itemsets\n",
      "0     0.65       (bread)\n",
      "1     0.35     (biscuit)\n",
      "2     0.30  (cornflakes)\n",
      "3     0.35         (tea)\n",
      "4     0.40      (coffee)\n",
      "\n",
      "Association rules:\n",
      "Empty DataFrame\n",
      "Columns: [antecedents, consequents, support, confidence]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "print(\"Frequent itemsets:\")\n",
    "print(frequent_itemsets.head())  # Display the first few items\n",
    "\n",
    "print(\"\\nAssociation rules:\")\n",
    "print(rules[['antecedents', 'consequents', 'support', 'confidence']].head(10))  # Display the first few rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the fp-growth algorithm from the mlxtend library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of rules : 0\n"
     ]
    }
   ],
   "source": [
    "start_fpgrowth = time.time()\n",
    "frequent_itemsets_fpgrowth = fpgrowth(data, min_support=min_support, use_colnames=True)  # Use column names if applicable\n",
    "\n",
    "# Generate association rules\n",
    "rules_fpgrowth = association_rules(frequent_itemsets_fpgrowth, metric=\"confidence\", min_threshold=min_confidence)\n",
    "print(\"No. of rules :\", len(rules_fpgrowth))\n",
    "\n",
    "end_fpgrowth = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time taken for FP Growth Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for FP-growth Algorithm: 2.1209716796875 ms\n"
     ]
    }
   ],
   "source": [
    "time_taken = (end_fpgrowth - start_fpgrowth)*1000\n",
    "print(\"Time taken for FP-growth Algorithm:\", time_taken, \"ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result of FP Growth Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequent itemsets:\n",
      "   support      itemsets\n",
      "0     0.65       (bread)\n",
      "1     0.35     (biscuit)\n",
      "2     0.30  (cornflakes)\n",
      "3     0.35         (tea)\n",
      "4     0.40      (coffee)\n",
      "\n",
      "Association rules:\n",
      "Empty DataFrame\n",
      "Columns: [antecedents, consequents, support, confidence]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "print(\"Frequent itemsets:\")\n",
    "print(frequent_itemsets_fpgrowth.head())  # Display the first few items\n",
    "\n",
    "print(\"\\nAssociation rules:\")\n",
    "print(rules_fpgrowth[['antecedents', 'consequents', 'support', 'confidence']].head(10))  # Display the first few rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
